# Cadenas de Markov

Taller de nivel *avanzado* sobre la teoría de cadenas de Markov.



## Información general

- Insitución: [GEM (UNI)](https://www.facebook.com/GEMFCUNI)

- Modalidad: Virtual

- Duración: 

   - Primera edición: 2021/11 - 2022/03
   - Segunda edición: **en proceso**

- Docentes: 

   - Jhon Astoquillca
   - [Daniel Camarena](https://github.com/DanielCamarena)
   - [David Morante](https://github.com/Dlay05)

- Clases:
   
   C-1. Presentación del taller - Nociones básicas de probabilidad y medida. [Material](https://drive.google.com/file/d/1CepqtQdvbajY97mqW1LFBpUlFdyIIhVh/view?usp=drive_link). [Anotaciones](https://drive.google.com/file/d/1EHBQ2XkpL3LoZe98-Bjbvw48jN62WTFH/view?usp=drive_link). [Grabación]().<br>
   C0. Esperanza condicional. [Material](https://drive.google.com/file/d/1mBELWlx_m4ajRfQfb6SCm2d6ytxAW6yC/view?usp=drive_link). [Anotaciones](https://drive.google.com/file/d/1d8IRJ3y0S-wzYba15R6HnmiDSUY2_H7o/view?usp=drive_link). [Grabación]().<br>
   C1. Introducción y motivaciones I. [Material](https://drive.google.com/file/d/1E94-ftrWjHKHCWnTnkkUM24Ck50-S111/view?usp=drive_link). [Anotaciones](https://drive.google.com/file/d/1uLosvHmo7unYaKjeHo1MurC8CLCf-NH0/view?usp=drive_link). [Grabación]().<br>
   C2. Introducción y motivaciones II. [Material](https://drive.google.com/file/d/1T67MzzIuBehqt_2gyOMcqzhyGhDFWOX1/view?usp=drive_link). [Anotaciones](https://drive.google.com/file/d/1S_wYp8Jxi1dYNZ2ZF5qZdswrzyu0u6at/view?usp=drive_link). [Grabación]().<br>
   L0. Introducción a python para computación científica. [Material](https://drive.google.com/file/d/1HN3yn3Sc_ZMYBQLCE2708WPVG0nS1prm/view?usp=drive_link). [Grabación]().<br>
   L1. Simulación de cadenas de Markov. [Material](https://drive.google.com/file/d/1fDIYc4UQO3z8ceqpMiFVExVfUbDl9RZx/view?usp=drive_link). [Grabación]().<br>
   C3. Espacio Canónico. [Material](https://drive.google.com/file/d/1qSmgLfvTlDNcJ45KrjIZLEjx3CMw7Aql/view?usp=drive_link). [Anotaciones](https://drive.google.com/file/d/1gK9Av_3sXzv_rOkph1Dti8Yqr2GQNETt/view?usp=drive_link). [Grabación]().<br>
   C4. Propiedad fuerte de Markov. [Material](https://drive.google.com/file/d/1zJlbZ4_LKCJ70yAXAUgdbHku23wzVeuu/view?usp=drive_link). [Anotaciones](https://drive.google.com/file/d/1u68RdJ1pocYW_Jz12f6KWn_y3F3_l32m/view?usp=drive_link). [Grabación]().<br>
   C5. Aplicaciones de la propiedad fuerte de Markov. [Material](https://drive.google.com/file/d/18Sn5BJmqcwKhoI6Ws5Qr27wP5bRhdzeg/view?usp=drive_link). [Anotaciones](https://drive.google.com/file/d/1L5nLhz8Q6PSFqbuvRE1GXyrBmc-F_uMw/view?usp=drive_link). [Grabación]().<br>
   L2. Propiedades de cadenas de Markov. [Material](https://drive.google.com/file/d/1UoFrzPSKj-N98Wbh9yJ7Ldmlf65F5X1A/view?usp=drive_link). [Grabación]().<br>
   L3. Repaso de teoría y simulación de cadenas de Markov. [Material](https://drive.google.com/file/d/10qRE0QOt3Klql7_foM9_2d12elcWCrZ3/view?usp=drive_link).<br>
   C6. Clasificación de estados. [Material](https://drive.google.com/file/d/1983Fd1UqAF8bHhRj49-W8Ek7p5o0JkDJ/view?usp=drive_link). [Anotaciones](https://drive.google.com/file/d/1hMyus9UctWjyu7Vrc-uNmkUVEKs_cItL/view?usp=drive_link). [Grabación]().<br>
   C7. Medidas invariantes. [Material](https://drive.google.com/file/d/1Xoewx7ynAzZ8oImw5yXDCk4uPTyoop8g/view?usp=drive_link). [Anotaciones](https://drive.google.com/file/d/191sp3zpSJLmvEbU2Vts4F251GMGvE7JG/view?usp=drive_link). [Grabación](). <br>
   L4. Cadenas de Markov y Método de Monte Carlo. [Material](https://drive.google.com/file/d/1PIsMeRDSEVrlsdi-TH92M_tEe-TwbeB3/view?usp=drive_link). [Grabación](). <br>
   C8. Comportamiento asintótico. [Material](https://drive.google.com/file/d/1auEFUUa6xT9X0drXT8bLHfwxfVk3_MNg/view?usp=drive_link). [Anotaciones](https://drive.google.com/file/d/1haJuEh0tI5LBdrJtM378xK641y9nuoLo/view?usp=drive_link). [Grabación](). <br>
   L5. Repaso de teoría y simulación de cadenas de Markov. [Material](https://drive.google.com/file/d/1UCnxyfAy9Lyzz5VZ05Ww0Gnh4WUCaPBN/view?usp=drive_link).<br>

- Descripción/Resumen: 
   
   [El presente taller propuesto persigue introducir a los participantes al mundo de la teoría de procesos estocásticos tomando como inicio del camino a la teoría ya clásica de cadenas de Markov. Se cubren los tópicos cruciales como la existencia de procesos que satisfagan la propiedad de Markov, clasificación del espacio de estados, estacionariedad y comportamiento asintótico. De hecho, se describirán los paseos aleatorios lo que permite establecer relaciones con la ecuación del calor en tiempo discreto y el movimiento Browniano. El enfoque a seguir será teórico-práctico con énfasis en el desarrollo de ejercicios y complementado con sesiones de simulación en Python.](https://www.facebook.com/GEMFCUNI/posts/pfbid0axQFuTPstJ6ErGkQgcYCQp5dgt2Kmou9Fp5NiwwxVtvVmohyUActGWZn4QP8cFAEl)
   
- Referencias
   
   B1. Le Gall, Integración, Probabilidades y Procesos aleatorios: Ecole normale supérieure de Paris. FIMFA <br>
   B1. Athreya and Lahiri, Measure Theory and Probability Theory, Springer <br>
   B1. Jacques Franchi, Procesos aleatorios en tiempo discreto <br>
   B2. Gregory Lawler, Random walk and the Heat Equation, 2010, AMS  <br>
   B3. Daniel Valesin, Markov Chain, Notes. <br>
   L1. [Sargent. Python Programming for Economics and Finance.](https://python-programming.quantecon.org/intro.html) <br>
   L1. [Sargent. Finite Markov Chains.](https://python.quantecon.org/finite_markov.html) <br>
   L2. [Stachurski. Economic Dynamics: Theory and Computation](https://johnstachurski.net/edtc.html) <br>


## Contacto

vcamarenap@uni.pe

